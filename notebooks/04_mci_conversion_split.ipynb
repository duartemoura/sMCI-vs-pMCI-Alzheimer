{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MCI Conversion Split (Improved)\n",
    "\n",
    "This notebook splits MCI subjects into pMCI and sMCI groups using ADNIMERGE.csv data:\n",
    "- **pMCI (progressive MCI)**: Subjects diagnosed with EMCI/LMCI/MCI at baseline who later converted to Dementia\n",
    "- **sMCI (stable MCI)**: Subjects diagnosed with EMCI/LMCI/MCI at baseline who remained MCI in all follow-ups **for at least 18 months**\n",
    "\n",
    "**Key improvements:**\n",
    "- Includes generic 'MCI' tag (ADNI1 patients with longest follow-up times)\n",
    "- Enforces minimum 18-month stability period for sMCI classification\n",
    "- Excludes subjects who revert to CN (ambiguous pathology)\n",
    "- Excludes subjects with insufficient follow-up data\n",
    "\n",
    "For subjects with multiple scans, only the earliest scan (lowest image ID) is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mci_path = Path(\"PATH_TO_DATA\")\n",
    "output_path = Path(\"PATH_TO_DATA\")\n",
    "pmci_path = output_path / \"pMCI\"\n",
    "smci_path = output_path / \"sMCI\"\n",
    "adnimerge_file = Path(\"PATH_TO_DATA\")\n",
    "\n",
    "pmci_path.mkdir(parents=True, exist_ok=True)\n",
    "smci_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_and_image_id(filename):\n",
    "    \"\"\"Extract subject ID and image ID from filename.\"\"\"\n",
    "    name_without_ext = filename.replace('.nii.gz', '').replace('.nii', '')\n",
    "    parts = name_without_ext.split('_')\n",
    "    \n",
    "    if len(parts) >= 4:\n",
    "        subject_id = f\"{parts[0]}_{parts[1]}_{parts[2]}\"\n",
    "        image_id_str = parts[3][1:]  # Remove 'I' prefix\n",
    "        try:\n",
    "            image_id = int(image_id_str)\n",
    "            return subject_id, image_id\n",
    "        except ValueError:\n",
    "            return subject_id, float('inf')\n",
    "    else:\n",
    "        return filename, float('inf')\n",
    "\n",
    "def get_earliest_scan_per_subject(file_list):\n",
    "    \"\"\"Group files by subject and return only the earliest scan for each subject.\"\"\"\n",
    "    subject_files = defaultdict(list)\n",
    "    \n",
    "    for filename in file_list:\n",
    "        subject_id, image_id = extract_subject_and_image_id(filename)\n",
    "        subject_files[subject_id].append((filename, image_id))\n",
    "    \n",
    "    earliest_scans = {}\n",
    "    for subject_id, files in subject_files.items():\n",
    "        files.sort(key=lambda x: x[1])\n",
    "        earliest_file = files[0][0]\n",
    "        earliest_scans[subject_id] = earliest_file\n",
    "        \n",
    "        if len(files) > 1:\n",
    "            print(f\"Subject {subject_id}: Selected {earliest_file} from {len(files)} scans\")\n",
    "    \n",
    "    return earliest_scans\n",
    "\n",
    "def determine_mci_conversion_status(adnimerge_df):\n",
    "    \"\"\"\n",
    "    Determine MCI conversion status from ADNIMERGE data.\n",
    "    \n",
    "    INCLUDES: Generic 'MCI' tag (ADNI1).\n",
    "    ENFORCES: Minimum 18-month stability for sMCI.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (conversion_status_dict, excluded_subjects_dict)\n",
    "        - conversion_status_dict: {PTID: 'pMCI' or 'sMCI'}\n",
    "        - excluded_subjects_dict: {PTID: reason_string}\n",
    "    \"\"\"\n",
    "    # 1. Fix: Include generic 'MCI' in baseline filter\n",
    "    mci_types = ['EMCI', 'LMCI', 'MCI']\n",
    "    mci_baseline = adnimerge_df[adnimerge_df['DX_bl'].isin(mci_types)]\n",
    "    \n",
    "    conversion_status = {}\n",
    "    excluded_subjects = {}  # Track excluded subjects with reasons\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {\"pMCI\": 0, \"sMCI\": 0, \"dropped_short_stable\": 0, \"dropped_reverter\": 0, \"dropped_no_data\": 0, \"dropped_inconsistent\": 0}\n",
    "    \n",
    "    for ptid, subject_data in mci_baseline.groupby('PTID'):\n",
    "        # Sort by date to be safe\n",
    "        subject_data = subject_data.sort_values('EXAMDATE')\n",
    "        \n",
    "        # Get follow up data\n",
    "        follow_ups = subject_data[subject_data['VISCODE'] != 'bl']\n",
    "        follow_up_dx = follow_ups['DX'].dropna().values\n",
    "        \n",
    "        if len(follow_up_dx) == 0:\n",
    "            stats[\"dropped_no_data\"] += 1\n",
    "            excluded_subjects[ptid] = \"NO_FOLLOWUP_DATA\"\n",
    "            continue\n",
    "            \n",
    "        # --- LOGIC TREE ---\n",
    "        \n",
    "        # 1. Did they EVER convert to Dementia? -> pMCI\n",
    "        if 'Dementia' in follow_up_dx:\n",
    "            conversion_status[ptid] = 'pMCI'\n",
    "            stats[\"pMCI\"] += 1\n",
    "            continue\n",
    "\n",
    "        # 2. Did they Revert to Normal (CN)? -> Exclude (Ambiguous pathology)\n",
    "        if 'CN' in follow_up_dx:\n",
    "            stats[\"dropped_reverter\"] += 1\n",
    "            excluded_subjects[ptid] = \"REVERTED_TO_CN\"\n",
    "            continue\n",
    "\n",
    "        # 3. sMCI Logic: Must contain ONLY MCI diagnoses AND span enough time\n",
    "        valid_mci_dx = {'EMCI', 'LMCI', 'MCI'}\n",
    "        is_consistent_mci = all(dx in valid_mci_dx for dx in follow_up_dx)\n",
    "        \n",
    "        if is_consistent_mci:\n",
    "            # Calculate time difference in months\n",
    "            dates = pd.to_datetime(subject_data['EXAMDATE'])\n",
    "            duration_days = (dates.max() - dates.min()).days\n",
    "            \n",
    "            # THRESHOLD: 540 days approx 18 months. \n",
    "            # Increasing this to 730 (2 years) is better if you can afford the data loss.\n",
    "            if duration_days >= 730: \n",
    "                conversion_status[ptid] = 'sMCI'\n",
    "                stats[\"sMCI\"] += 1\n",
    "            else:\n",
    "                stats[\"dropped_short_stable\"] += 1\n",
    "                excluded_subjects[ptid] = f\"STABLE_BUT_SHORT ({duration_days} days < 730 days)\"\n",
    "        else:\n",
    "            # Fluctuating or missing data\n",
    "            stats[\"dropped_inconsistent\"] += 1\n",
    "            excluded_subjects[ptid] = f\"INCONSISTENT_DX ({list(follow_up_dx)})\"\n",
    "\n",
    "    print(\"\\n--- Final Dataset Stats ---\")\n",
    "    print(f\"pMCI: {stats['pMCI']}\")\n",
    "    print(f\"sMCI: {stats['sMCI']}\")\n",
    "    print(f\"Dropped (Stable < 18 months): {stats['dropped_short_stable']}\")\n",
    "    print(f\"Dropped (Reverted to CN): {stats['dropped_reverter']}\")\n",
    "    print(f\"Dropped (No follow-up data): {stats['dropped_no_data']}\")\n",
    "    print(f\"Dropped (Inconsistent diagnoses): {stats['dropped_inconsistent']}\")\n",
    "    print(f\"Total MCI baseline subjects: {len(mci_baseline.groupby('PTID'))}\")\n",
    "    print(f\"Total classified: {len(conversion_status)}\")\n",
    "    print(f\"Total excluded: {len(excluded_subjects)}\")\n",
    "    \n",
    "    return conversion_status, excluded_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ADNIMERGE Data and Determine Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ADNIMERGE data\n",
    "try:\n",
    "    print(\"Loading ADNIMERGE.csv...\")\n",
    "    adnimerge_df = pd.read_csv(adnimerge_file, low_memory=False)\n",
    "    print(f\"Loaded {len(adnimerge_df)} records from ADNIMERGE\")\n",
    "    \n",
    "    # Determine conversion status\n",
    "    print(\"Determining MCI conversion status...\")\n",
    "    conversion_status, excluded_subjects = determine_mci_conversion_status(adnimerge_df)\n",
    "    \n",
    "    pmci_subjects = [ptid for ptid, status in conversion_status.items() if status == 'pMCI']\n",
    "    smci_subjects = [ptid for ptid, status in conversion_status.items() if status == 'sMCI']\n",
    "    \n",
    "    print(f\"\\nConversion analysis results:\")\n",
    "    print(f\"pMCI (progressive): {len(pmci_subjects)} subjects\")\n",
    "    print(f\"sMCI (stable): {len(smci_subjects)} subjects\")\n",
    "    print(f\"Total classified: {len(conversion_status)} subjects\")\n",
    "    if len(conversion_status) > 0:\n",
    "        print(f\"Conversion rate: {len(pmci_subjects) / len(conversion_status) * 100:.1f}%\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: ADNIMERGE file not found at {adnimerge_file}\")\n",
    "    conversion_status = {}\n",
    "    excluded_subjects = {}\n",
    "    pmci_subjects = []\n",
    "    smci_subjects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process MCI Files and Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check which subjects from files are not in ADNIMERGE\n",
    "print(\"=== DIAGNOSTIC: Checking subjects not found in ADNIMERGE ===\\n\")\n",
    "\n",
    "# Get all subject IDs from files\n",
    "mci_files = [f for f in os.listdir(mci_path) if f.endswith('.nii.gz')]\n",
    "file_subject_ids = set()\n",
    "for filename in mci_files:\n",
    "    subject_id, _ = extract_subject_and_image_id(filename)\n",
    "    file_subject_ids.add(subject_id)\n",
    "\n",
    "print(f\"Total unique subjects in TAU MCI files: {len(file_subject_ids)}\")\n",
    "\n",
    "# Get all PTIDs from ADNIMERGE\n",
    "adnimerge_ptids = set(adnimerge_df['PTID'].unique())\n",
    "print(f\"Total unique PTIDs in ADNIMERGE: {len(adnimerge_ptids)}\")\n",
    "\n",
    "# Find missing subjects\n",
    "missing_subjects = file_subject_ids - adnimerge_ptids\n",
    "found_subjects = file_subject_ids & adnimerge_ptids\n",
    "\n",
    "print(f\"\\nSubjects found in ADNIMERGE: {len(found_subjects)}\")\n",
    "print(f\"Subjects NOT in ADNIMERGE: {len(missing_subjects)}\")\n",
    "\n",
    "if missing_subjects:\n",
    "    print(f\"\\n--- First 20 subjects NOT in ADNIMERGE ---\")\n",
    "    for i, subject_id in enumerate(sorted(missing_subjects)[:20]):\n",
    "        print(f\"  {subject_id}\")\n",
    "    \n",
    "    # Check if there's a pattern - maybe they're formatted differently?\n",
    "    print(f\"\\n--- Checking for format variations ---\")\n",
    "    # Try looking for variations (with/without leading zeros, etc.)\n",
    "    sample_missing = list(missing_subjects)[:5]\n",
    "    for subject_id in sample_missing:\n",
    "        parts = subject_id.split('_')\n",
    "        if len(parts) == 3:\n",
    "            site, s, num = parts\n",
    "            # Try variations\n",
    "            variations = [\n",
    "                subject_id,\n",
    "                f\"{int(site)}_{s}_{int(num)}\",  # Remove leading zeros\n",
    "                f\"{site}_{s}_{num.zfill(4)}\",  # Add more zeros\n",
    "            ]\n",
    "            found_variations = []\n",
    "            for var in variations:\n",
    "                if var in adnimerge_ptids:\n",
    "                    found_variations.append(var)\n",
    "            if found_variations:\n",
    "                print(f\"  {subject_id} -> Found as: {found_variations}\")\n",
    "            else:\n",
    "                print(f\"  {subject_id} -> Not found in any variation\")\n",
    "    \n",
    "    # Check if subjects exist but with different baseline diagnoses\n",
    "    print(f\"\\n--- Checking if missing subjects exist with non-MCI baseline ---\")\n",
    "    sample_missing = list(missing_subjects)[:10]\n",
    "    for subject_id in sample_missing:\n",
    "        # Try partial match - maybe the format is slightly different\n",
    "        matching_rows = adnimerge_df[adnimerge_df['PTID'].str.contains(subject_id.split('_')[-1], na=False)]\n",
    "        if len(matching_rows) > 0:\n",
    "            unique_ptids = matching_rows['PTID'].unique()\n",
    "            print(f\"  {subject_id} -> Found similar PTIDs: {list(unique_ptids)[:3]}\")\n",
    "            # Check baseline diagnoses\n",
    "            for ptid in unique_ptids[:1]:\n",
    "                baseline_rows = adnimerge_df[(adnimerge_df['PTID'] == ptid) & (adnimerge_df['VISCODE'] == 'bl')]\n",
    "                if len(baseline_rows) > 0:\n",
    "                    dx_bl = baseline_rows.iloc[0]['DX_bl']\n",
    "                    print(f\"      Baseline DX: {dx_bl}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MCI files and select earliest per subject\n",
    "mci_files = [f for f in os.listdir(mci_path) if f.endswith('.nii.gz')]\n",
    "print(f\"Found {len(mci_files)} MCI files\")\n",
    "\n",
    "earliest_scans = get_earliest_scan_per_subject(mci_files)\n",
    "print(f\"After selecting earliest scans: {len(earliest_scans)} unique subjects\")\n",
    "\n",
    "# Split into pMCI and sMCI based on conversion status\n",
    "pmci_count = smci_count = unclassified_count = 0\n",
    "unclassified_reasons = defaultdict(int)\n",
    "unclassified_examples = []  # Store examples for display\n",
    "\n",
    "for subject_id, filename in tqdm(earliest_scans.items(), desc=\"Splitting MCI subjects\"):\n",
    "    source_path = mci_path / filename\n",
    "    \n",
    "    # Check conversion status\n",
    "    if subject_id in conversion_status:\n",
    "        status = conversion_status[subject_id]\n",
    "        if status == 'pMCI':\n",
    "            dest_path = pmci_path / filename\n",
    "            pmci_count += 1\n",
    "        else:  # sMCI\n",
    "            dest_path = smci_path / filename\n",
    "            smci_count += 1\n",
    "        \n",
    "        # Copy file if it doesn't exist\n",
    "        if not dest_path.exists():\n",
    "            shutil.copy(source_path, dest_path)\n",
    "    else:\n",
    "        unclassified_count += 1\n",
    "        \n",
    "        # Check if subject is in excluded_subjects (from conversion analysis)\n",
    "        if subject_id in excluded_subjects:\n",
    "            reason = excluded_subjects[subject_id]\n",
    "            unclassified_reasons[reason] += 1\n",
    "            if len(unclassified_examples) < 10:  # Store first 10 examples\n",
    "                unclassified_examples.append((subject_id, reason))\n",
    "        else:\n",
    "            # Subject not in ADNIMERGE or doesn't have MCI baseline\n",
    "            subject_data = adnimerge_df[adnimerge_df['PTID'] == subject_id]\n",
    "            if len(subject_data) == 0:\n",
    "                reason = \"NOT_IN_ADNIMERGE\"\n",
    "            else:\n",
    "                baseline = subject_data[subject_data['VISCODE'] == 'bl']\n",
    "                if len(baseline) == 0:\n",
    "                    reason = \"NO_BASELINE_IN_ADNIMERGE\"\n",
    "                else:\n",
    "                    dx_bl = baseline.iloc[0]['DX_bl']\n",
    "                    reason = f\"BASELINE_NOT_MCI ({dx_bl})\"\n",
    "            \n",
    "            unclassified_reasons[reason] += 1\n",
    "            if len(unclassified_examples) < 10:\n",
    "                unclassified_examples.append((subject_id, reason))\n",
    "\n",
    "print(f\"\\nSplitting completed:\")\n",
    "print(f\"pMCI (progressive): {pmci_count} subjects\")\n",
    "print(f\"sMCI (stable): {smci_count} subjects\")\n",
    "print(f\"Unclassified: {unclassified_count} subjects\")\n",
    "if pmci_count + smci_count > 0:\n",
    "    print(f\"Conversion rate: {pmci_count / (pmci_count + smci_count) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n--- Unclassified Subjects Breakdown ---\")\n",
    "print(\"(Subjects from files that are not in conversion_status)\")\n",
    "for reason, count in sorted(unclassified_reasons.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{reason}: {count}\")\n",
    "\n",
    "if unclassified_examples:\n",
    "    print(f\"\\n--- Example Unclassified Subjects (first 10) ---\")\n",
    "    for subject_id, reason in unclassified_examples:\n",
    "        print(f\"  {subject_id}: {reason}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splits\n",
    "pmci_files_created = len([f for f in os.listdir(pmci_path) if f.endswith('.nii.gz')])\n",
    "smci_files_created = len([f for f in os.listdir(smci_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "print(f\"\\nFinal verification:\")\n",
    "print(f\"pMCI directory: {pmci_files_created} files\")\n",
    "print(f\"sMCI directory: {smci_files_created} files\")\n",
    "print(f\"Total processed: {pmci_files_created + smci_files_created} files\")\n",
    "\n",
    "# Show some example PTIDs for each group\n",
    "if pmci_subjects:\n",
    "    print(f\"\\nExample pMCI subjects: {pmci_subjects[:5]}\")\n",
    "if smci_subjects:\n",
    "    print(f\"Example sMCI subjects: {smci_subjects[:5]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
