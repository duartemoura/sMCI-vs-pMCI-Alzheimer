{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create k-Fold Datasets for MCI Progression\n",
    "\n",
    "This notebook takes the separated pMCI and sMCI datasets and creates 5-fold cross-validation splits. This is a crucial step for training a robust model for predicting MCI to AD conversion.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "1.  **File Shuffling**: The lists of pMCI and sMCI files are shuffled randomly to ensure that the folds are not biased by the original file order.\n",
    "2.  **Fold Creation**: The shuffled lists are divided into 5 equal parts. For each of the 5 iterations (folds):\n",
    "    *   One part is designated as the **validation set**.\n",
    "    *   The remaining four parts are combined to form the **training set**.\n",
    "3.  **Preprocessing**: Each image in the training and validation sets for a given fold is preprocessed using the same 3D pipeline as before (conform, skull-strip, normalize).\n",
    "4.  **Saving**: The processed images and their corresponding labels for each training and validation set are saved as individual pickled dictionary files. This results in 10 files (5 for training, 5 for validation), each containing PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths for the split MCI data\n",
    "mci_split_path = Path(\"PATH_TO_DATA\")\n",
    "pmci_path = mci_split_path / \"pMCI_stripped\"\n",
    "smci_path = mci_split_path / \"sMCI_stripped\"\n",
    "\n",
    "# Output path for k-fold datasets\n",
    "kfold_output_path = Path(\"./data/processed/kfold_fdg_final_run/\")\n",
    "kfold_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cc3d \n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import binary_erosion, binary_dilation, binary_fill_holes, zoom\n",
    "\n",
    "\n",
    "def resize_volume(volume, target_shape=(100, 100, 90)):\n",
    "    \"\"\"\n",
    "    Resize 3D volume to target shape using trilinear interpolation.\n",
    "    \n",
    "    Args:\n",
    "        volume: 3D numpy array\n",
    "        target_shape: tuple of target dimensions (height, width, depth)\n",
    "    \n",
    "    Returns:\n",
    "        Resized 3D numpy array\n",
    "    \"\"\"\n",
    "    current_shape = volume.shape\n",
    "    zoom_factors = [target_shape[i] / current_shape[i] for i in range(3)]\n",
    "    return zoom(volume, zoom_factors, order=1)  # order=1 for trilinear interpolation\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, use_brain_mask=True):\n",
    "    \"\"\"\n",
    "    Load a NIfTI image, resize to 100x100x90, and normalize intensities to [0,1].\n",
    "    \n",
    "    IMPORTANT: Resizing is done BEFORE masking to prevent interpolation from\n",
    "    ruining the brain mask!\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to NIfTI file\n",
    "        use_brain_mask: Whether to apply brain masking (default True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the NIfTI image\n",
    "        input_img = nib.load(image_path)\n",
    "        img_data = input_img.get_fdata()\n",
    "\n",
    "        # Handle 4D images by taking the first volume\n",
    "        if img_data.ndim == 4:\n",
    "            print(f\"Note: 4D image detected, using first volume: {image_path.name}\")\n",
    "            img_data = img_data[..., 0]\n",
    "        elif img_data.ndim != 3:\n",
    "            print(f\"Error: Unsupported image dimensions {img_data.shape}: {image_path.name}\")\n",
    "            return None\n",
    "        \n",
    "        # STEP 1: Resize to target dimensions (100, 100, 90)\n",
    "        img_data = resize_volume(img_data, target_shape=(100, 100, 90))\n",
    "\n",
    "        # STEP 2: Intensity normalization to [0,1]\n",
    "        img_min, img_max = img_data.min(), img_data.max()\n",
    "        if img_max > img_min:  # avoid divide-by-zero\n",
    "            img_data = (img_data - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            img_data = np.zeros_like(img_data)\n",
    "\n",
    "        return img_data.astype(np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Organize Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file lists\n",
    "pmci_files = sorted([pmci_path / f for f in os.listdir(pmci_path) if f.endswith('.nii.gz')])\n",
    "smci_files = sorted([smci_path / f for f in os.listdir(smci_path) if f.endswith('.nii.gz')])\n",
    "\n",
    "print(f\"Found {len(pmci_files)} pMCI files\")\n",
    "print(f\"Found {len(smci_files)} sMCI files\")\n",
    "\n",
    "# Create labels (1 for pMCI/converter, 0 for sMCI/stable)\n",
    "pmci_labels = [1] * len(pmci_files)\n",
    "smci_labels = [0] * len(smci_files)\n",
    "\n",
    "# Extract subject IDs\n",
    "def extract_subject_id(filepath):\n",
    "    # Extracts subject ID like '002_S_0729' from the full path\n",
    "    name = filepath.stem.split('.')[0]  # remove .nii\n",
    "    parts = name.split('_')\n",
    "    return f\"{parts[0]}_{parts[1]}_{parts[2]}\"\n",
    "\n",
    "pmci_subjects = [extract_subject_id(f) for f in pmci_files]\n",
    "smci_subjects = [extract_subject_id(f) for f in smci_files]\n",
    "\n",
    "# Combine files, labels, and subjects\n",
    "all_files = pmci_files + smci_files\n",
    "all_labels = pmci_labels + smci_labels\n",
    "all_subjects = pmci_subjects + smci_subjects\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "all_files = np.array(all_files)\n",
    "all_labels = np.array(all_labels)\n",
    "all_subjects = np.array(all_subjects)\n",
    "\n",
    "print(f\"Total files: {len(all_files)}\")\n",
    "print(f\"pMCI/sMCI ratio: {len(pmci_files)}/{len(smci_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create K-Fold Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratified k-fold splits to maintain class balance\n",
    "kfold = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(all_files, all_labels)):\n",
    "    print(f\"\\n--- Processing Fold {fold_idx + 1} ---\")\n",
    "    \n",
    "    # Get train and validation sets for this fold\n",
    "    train_files, train_labels, train_subjects = all_files[train_indices], all_labels[train_indices], all_subjects[train_indices]\n",
    "    val_files, val_labels, val_subjects = all_files[val_indices], all_labels[val_indices], all_subjects[val_indices]\n",
    "    \n",
    "    print(f\"Train: {len(train_files)} files (pMCI: {np.sum(train_labels)}, sMCI: {len(train_labels) - np.sum(train_labels)})\")\n",
    "    print(f\"Val: {len(val_files)} files (pMCI: {np.sum(val_labels)}, sMCI: {len(val_labels) - np.sum(val_labels)})\")\n",
    "\n",
    "    # Process and save function\n",
    "    def process_and_save_fold(files, labels, subjects, fold_type, fold_num):\n",
    "        print(f\"Processing {fold_type} data...\")\n",
    "        images, valid_labels, valid_subjects = [], [], []\n",
    "        \n",
    "        for i, file_path in enumerate(tqdm(files, desc=f\"{fold_type.capitalize()} images\")):\n",
    "            processed = preprocess_image(file_path)\n",
    "            if processed is not None:\n",
    "                # Add channel dimension for 3D CNNs\n",
    "                images.append(np.expand_dims(processed, axis=0))  # (1, D, H, W)\n",
    "                valid_labels.append(labels[i])\n",
    "                valid_subjects.append(subjects[i])\n",
    "        \n",
    "        if images:\n",
    "            data_dict = {\n",
    "                \"images\": torch.tensor(np.array(images)),\n",
    "                \"labels\": torch.tensor(valid_labels),\n",
    "                \"subject_ids\": np.array(valid_subjects)\n",
    "            }\n",
    "            file_name = kfold_output_path / f\"{fold_type}_fold_{fold_num}.pkl\"\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(data_dict, f)\n",
    "            print(f\"Saved {len(images)} {fold_type} images to {file_name}\")\n",
    "\n",
    "    # Process and save for the current fold\n",
    "    process_and_save_fold(train_files, train_labels, train_subjects, \"train\", fold_idx + 1)\n",
    "    process_and_save_fold(val_files, val_labels, val_subjects, \"val\", fold_idx + 1)\n",
    "\n",
    "print(\"\\nK-fold dataset creation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save K-Fold Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata about the k-fold splits\n",
    "kfold_info = {\n",
    "    \"num_folds\": NUM_FOLDS,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"total_pmci_files\": len(pmci_files),\n",
    "    \"total_smci_files\": len(smci_files),\n",
    "    \"fold_files\": {\n",
    "        f\"fold_{i+1}\": {\n",
    "            \"train_file\": f\"train_fold_{i+1}.pkl\",\n",
    "            \"val_file\": f\"val_fold_{i+1}.pkl\"\n",
    "        } for i in range(NUM_FOLDS)\n",
    "    }\n",
    "}\n",
    "\n",
    "info_file = kfold_output_path / \"kfold_info.pkl\"\n",
    "with open(info_file, 'wb') as f:\n",
    "    pickle.dump(kfold_info, f)\n",
    "\n",
    "print(f\"K-fold information saved to {info_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs processed image comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a random fold\n",
    "random_fold = np.random.randint(1, NUM_FOLDS + 1)\n",
    "train_file = kfold_output_path / f\"train_fold_{random_fold}.pkl\"\n",
    "\n",
    "with open(train_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# Select a random image\n",
    "random_idx = np.random.randint(0, len(train_data['images']))\n",
    "processed_image = train_data['images'][random_idx].numpy()\n",
    "random_label = train_data['labels'][random_idx].item()\n",
    "random_subject = train_data['subject_ids'][random_idx]\n",
    "\n",
    "# Remove channel dimension from processed image\n",
    "if processed_image.ndim == 4 and processed_image.shape[0] == 1:\n",
    "    processed_image = processed_image.squeeze(0)\n",
    "elif processed_image.ndim == 4:\n",
    "    print(f\"Warning: Unexpected 4D shape: {processed_image.shape}\")\n",
    "    processed_image = processed_image[0]\n",
    "\n",
    "# Load the ORIGINAL unprocessed image\n",
    "label_name = \"pMCI\" if random_label == 1 else \"sMCI\"\n",
    "original_dir = pmci_path if random_label == 1 else smci_path\n",
    "\n",
    "# Find the original file for this subject\n",
    "original_file = None\n",
    "for f in original_dir.glob('*.nii.gz'):\n",
    "    if random_subject in f.name:\n",
    "        original_file = f\n",
    "        break\n",
    "\n",
    "if original_file is None:\n",
    "    print(f\"ERROR: Could not find original file for subject {random_subject}\")\n",
    "else:\n",
    "    # Load original image\n",
    "    original_img = nib.load(original_file)\n",
    "    original_data = original_img.get_fdata()\n",
    "    if original_data.ndim == 4:\n",
    "        original_data = original_data[..., 0]\n",
    "    \n",
    "    # Resize original to match processed for comparison\n",
    "    from scipy.ndimage import zoom\n",
    "    zoom_factors = [processed_image.shape[i] / original_data.shape[i] for i in range(3)]\n",
    "    original_resized = zoom(original_data, zoom_factors, order=1)\n",
    "    \n",
    "    # Normalize original to [0,1] for display\n",
    "    orig_min, orig_max = original_resized.min(), original_resized.max()\n",
    "    if orig_max > orig_min:\n",
    "        original_resized = (original_resized - orig_min) / (orig_max - orig_min)\n",
    "    \n",
    "    # Get the middle slice\n",
    "    width_slice = processed_image.shape[2] // 2\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Original (unprocessed)\n",
    "    axes[0].imshow(original_resized[:, :, width_slice], cmap='gray')\n",
    "    axes[0].set_title('ORIGINAL (Unprocessed)\\nWith Skull', fontsize=12, fontweight='bold', color='red')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Processed (with brain masking)\n",
    "    axes[1].imshow(processed_image[:, :, width_slice], cmap='gray')\n",
    "    axes[1].set_title('PROCESSED (Brain Masked)\\nSkull Removed', fontsize=12, fontweight='bold', color='green')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Sagittal View Comparison - Subject: {random_subject} ({label_name}) - Fold {random_fold}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save comparison\n",
    "    sagittal_output_path = kfold_output_path / \"visualizations\"\n",
    "    sagittal_output_path.mkdir(exist_ok=True)\n",
    "    comparison_filename = sagittal_output_path / f\"comparison_fold{random_fold}_{random_subject}_{label_name}.png\"\n",
    "    plt.savefig(comparison_filename, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Comparison saved to {comparison_filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nSubject ID: {random_subject}\")\n",
    "    print(f\"Label: {label_name} ({random_label})\")\n",
    "    print(f\"Original file: {original_file.name}\")\n",
    "    print(f\"Original shape: {original_data.shape}\")\n",
    "    print(f\"Processed shape: {processed_image.shape}\")\n",
    "    print(f\"\\nOriginal non-zero voxels: {(original_resized > 0).sum()}\")\n",
    "    print(f\"Processed non-zero voxels: {(processed_image > 0).sum()}\")\n",
    "    print(f\"Voxels removed by masking: {(original_resized > 0).sum() - (processed_image > 0).sum()}\")\n",
    "    print(f\"Percentage removed: {100 * (1 - (processed_image > 0).sum() / (original_resized > 0).sum()):.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
