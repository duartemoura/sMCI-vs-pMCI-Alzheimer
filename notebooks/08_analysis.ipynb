{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Analysis and Visualization of Results\n",
    "\n",
    "This final notebook consolidates all the generated data to perform a comprehensive analysis of the MCI conversion prediction model. It replicates the analyses from the original `Results dataset.ipynb`, `Metrics(new).ipynb`, `Demographics.ipynb`, and `Time to conversion.ipynb`.\n",
    "\n",
    "The key analyses include:\n",
    "\n",
    "1.  **Data Loading and Merging**: Loads the Monte Carlo dropout results, demographic information, and time-to-conversion data, merging them into a single master DataFrame.\n",
    "2.  **Performance Metrics**: Calculates and displays key performance metrics for the model, including:\n",
    "    *   Area Under the ROC Curve (AUC).\n",
    "    *   Accuracy, Sensitivity, and Specificity at the optimal threshold (determined by G-Mean).\n",
    "    *   Precision-Recall Curve and Confusion Matrix.\n",
    "3.  **Correlation Analysis**: Investigates the relationships between the model's predictions (and uncertainty) and various clinical/demographic variables using correlation matrices and scatter plots.\n",
    "4.  **Time-to-Conversion Analysis**: Explores the model's performance in predicting conversion at different time intervals (e.g., 1-year, 2-year recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, precision_recall_curve, ConfusionMatrixDisplay\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "results_path = Path(\"./results/\")\n",
    "mc_results_file = results_path / \"mci_mc_dropout_results.pkl\"\n",
    "demographics_file = Path(\"./original_notebooks/excels/processed_demog.xlsx\")\n",
    "conversion_file = Path(\"./original_notebooks/excels/conv_with_time.xlsx\")\n",
    "adnimerge_file = Path(\"./data/raw/ADNIMERGE.csv\")  # For full demographic info\n",
    "\n",
    "# Load data\n",
    "mc_df = pd.read_pickle(mc_results_file)\n",
    "\n",
    "# It is better practice to load the full ADNIMERGE file for demographic data\n",
    "# This ensures all subjects from the experiment can be found.\n",
    "print(\"Loading ADNIMERGE for demographic and clinical data...\")\n",
    "demog_df = pd.read_csv(adnimerge_file, low_memory=False)\n",
    "# Get baseline data for each subject\n",
    "demog_df_baseline = demog_df[demog_df['VISCODE'] == 'bl']\n",
    "\n",
    "# Merge MC results with demographic data\n",
    "# The subject ID in our results is the 'PTID' in ADNIMERGE\n",
    "results_df = pd.merge(mc_df, demog_df_baseline, left_on='subject_id', right_on='PTID', how='left')\n",
    "results_df.rename(columns={\"label\": \"Conversion\"}, inplace=True)\n",
    "\n",
    "print(f\"Merged DataFrame shape: {results_df.shape}\")\n",
    "print(\"\\nMerged DataFrame Head:\")\n",
    "display(results_df.head())\n",
    "\n",
    "# Check for any subjects that didn't merge\n",
    "if results_df['PTID'].isnull().any():\n",
    "    print(\"\\nWarning: Some subjects from MC results were not found in ADNIMERGE baseline data.\")\n",
    "    print(results_df[results_df['PTID'].isnull()]['subject_id'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Performance Metrics ---\n",
    "y_true = results_df[\"Conversion\"]\n",
    "y_pred_prob = results_df[\"mc_mean\"]\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred_prob)\n",
    "print(f\"Overall AUC: {auc:.4f}\")\n",
    "\n",
    "# Find best threshold using G-Mean\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "best_thresh_idx = np.argmax(gmeans)\n",
    "best_thresh = thresholds[best_thresh_idx]\n",
    "print(f\"Best Threshold (G-Mean): {best_thresh:.4f}\")\n",
    "\n",
    "# Predictions based on best threshold\n",
    "y_pred_class = (y_pred_prob >= best_thresh).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_class)\n",
    "print(f\"Accuracy at Best Threshold: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_class)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"Positive Predictive Value (PPV): {ppv:.4f}\")\n",
    "print(f\"Negative Predictive Value (NPV): {npv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='No Skill')\n",
    "plt.scatter(fpr[best_thresh_idx], tpr[best_thresh_idx], marker='o', color='black', label='Best Threshold')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for MCI Conversion Prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix Display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['sMCI', 'pMCI'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between predictions/uncertainty and other variables\n",
    "# Update column names to match ADNIMERGE\n",
    "# e.g., 'Age' is 'AGE', 'MMSE_dem' is 'MMSE', etc.\n",
    "# Check your ADNIMERGE.csv for the exact column names. I will use common ones.\n",
    "cols_to_correlate = [\n",
    "    \"mc_mean\", \"mc_std\", \"AGE\", \"PTEDUCAT\", \n",
    "    \"APOE4\", \"MMSE\", \"MOCA\", \"ADAS13\", \"FAQ\"\n",
    "]\n",
    "# Filter for columns that actually exist in the dataframe\n",
    "existing_cols = [col for col in cols_to_correlate if col in results_df.columns]\n",
    "\n",
    "correlation_df = results_df[existing_cols].dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_df.corr(method='pearson'), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Pearson Correlation Matrix of Predictions and Clinical Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of prediction vs. uncertainty\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=results_df, x=\"mc_mean\", y=\"mc_std\", hue=\"Conversion\")\n",
    "plt.title(\"Prediction Mean vs. Standard Deviation\")\n",
    "plt.xlabel(\"Mean Prediction (pMCI Probability)\")\n",
    "plt.ylabel(\"Prediction Standard Deviation (Uncertainty)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
